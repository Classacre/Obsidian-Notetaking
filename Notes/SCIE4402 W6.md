---
Class: University
Status: Working
Priority: High
Week: 6
Lecture:
  - ðŸŸ¥
Flashcards:
  - ðŸŸ¥
tags:
---
> Error generating daily quote

---
# Notes for SCIE4402 W6
### **Regression**

**Assumptions and Tests**

1. **Linearity**
   - **Test:**  
     - **Visual Inspection:** Plot residuals vs. fitted values.
     - **RESET Test:** Assess model specification.
   - **R Code:**
     ```R
     # Visual Inspection
     plot(model$residuals ~ model$fitted.values, main="Residuals vs Fitted")
     abline(h=0, col="red", lty=2)

     # RESET Test
     library(lmtest)
     resettest(model, data=your_data)
     ```

   - **If Assumption Fails:**  
     - Apply transformations (e.g., log, square) or add polynomial terms.
     - **R Code Example:**
       ```R
       # Log Transformation
       model_transformed <- lm(log(Y) ~ X, data=your_data)
       summary(model_transformed)

       # Adding Polynomial Term
       model_poly <- lm(Y ~ X + I(X^2), data=your_data)
       summary(model_poly)
       ```

2. **Independence**
   - **Test:**  
     - **Autocorrelation Test (for time series):** Breusch-Godfrey Test.
   - **R Code:**
     ```R
     library(lmtest)
     bgtest(model)
     ```

   - **If Assumption Fails:**  
     - Use Generalized Least Squares (GLS) to model autocorrelation.
     - **R Code Example:**
       ```R
       library(nlme)
       model_gls <- gls(Y ~ X, correlation=corARMA(p=1, q=0), data=your_data)
       summary(model_gls)
       ```

3. **Homoscedasticity (Constant Variance)**
   - **Test:**  
     - **Breusch-Pagan Test:** Check for non-constant error variance.
   - **R Code:**
     ```R
     library(lmtest)
     bptest(model)
     ```

   - **If Assumption Fails:**  
     - Apply Robust Standard Errors.
     - **R Code Example:**
       ```R
       library(sandwich)
       library(lmtest)
       coeftest(model, vcov = vcovHC(model, type = "HC3"))
       ```

     - **Alternatively, Use GLS with Heteroskedasticity:**
       ```R
       library(nlme)
       model_gls_hetro <- gls(Y ~ X, weights=varPower(), data=your_data)
       summary(model_gls_hetro)
       ```

4. **Normality of Residuals**
   - **Test:**  
     - **Shapiro-Wilk Test:** Assess if residuals are normally distributed.
   - **R Code:**
     ```R
     shapiro.test(model$residuals)
     ```

   - **If Assumption Fails:**  
     - Consider data transformations or use non-parametric methods.
     - **R Code Example:**
       ```R
       # Log Transformation
       model_transformed <- lm(log(Y) ~ X, data=your_data)
       shapiro.test(model_transformed$residuals)
       ```

5. **Multicollinearity**
   - **Test:**  
     - **Variance Inflation Factor (VIF):** Detect multicollinearity among predictors.
   - **R Code:**
     ```R
     library(car)
     vif(model)
     ```

   - **If Assumption Fails:**  
     - Remove or combine highly correlated predictors.
     - **R Code Example:**
       ```R
       # Removing a Predictor
       model_reduced <- lm(Y ~ X1 + X2, data=your_data)
       summary(model_reduced)

       # Combining Predictors
       your_data$Combined_X <- your_data$X1 + your_data$X2
       model_combined <- lm(Y ~ Combined_X, data=your_data)
       summary(model_combined)
       ```

---

### **ANOVA**

**Assumptions and Tests**

1. **Independence of Observations**
   - **Test:**  
     - Ensure experimental or study design provides independent samples.
   - **R Code:**  
     - Typically verified through study design; no specific R code.

   - **If Assumption Fails:**  
     - Consider using repeated measures ANOVA or mixed-effects models.
     - **R Code Example:**
       ```R
       library(nlme)
       model_mixed <- lme(Y ~ Factor, random = ~1 | Subject, data=your_data)
       summary(model_mixed)
       ```

2. **Homogeneity of Variances (Homoscedasticity)**
   - **Test:**  
     - **Bartlettâ€™s Test:** Suitable for normally distributed data.
     - **Leveneâ€™s Test:** More robust to departures from normality.
   - **R Code:**
     ```R
     # Bartlettâ€™s Test
     bartlett.test(Y ~ Group, data=your_data)

     # Leveneâ€™s Test
     library(car)
     leveneTest(Y ~ Group, data=your_data)
     ```

   - **If Assumption Fails:**  
     - Use Robust ANOVA methods or transform data.
     - **R Code Example:**
       ```R
       library(car)
       Anova(lm(Y ~ Group, data=your_data), vcov.=vcovHC(lm(Y ~ Group, data=your_data)))

       # Alternatively, apply transformation
       your_data$log_Y <- log(your_data$Y)
       model_transformed <- lm(log_Y ~ Group, data=your_data)
       summary(model_transformed)
       ```

3. **Normality Within Groups**
   - **Test:**  
     - **Shapiro-Wilk Test:** Perform within each group.
   - **R Code:**
     ```R
     library(dplyr)
     your_data %>%
       group_by(Group) %>%
       summarise(p_value = shapiro.test(Y)$p.value)
     ```

   - **If Assumption Fails:**  
     - Apply data transformations or use non-parametric alternatives like the Kruskal-Wallis test.
     - **R Code Example:**
       ```R
       # Kruskal-Wallis Test
       kruskal.test(Y ~ Group, data=your_data)

       # Alternatively, transform data
       your_data$log_Y <- log(your_data$Y)
       model_transformed <- lm(log_Y ~ Group, data=your_data)
       summary(model_transformed)
       ```

4. **No Interaction Effects (for Factorial ANOVA)**
   - **Test:**  
     - **Interaction Plots:** Visual assessment for interactions.
   - **R Code:**
     ```R
     interaction.plot(your_data$FactorA, your_data$FactorB, your_data$Y, type="b")
     ```

   - **If Interaction Exists:**  
     - Include interaction terms in the model.
     - **R Code Example:**
       ```R
       model_interaction <- lm(Y ~ FactorA * FactorB, data=your_data)
       summary(model_interaction)
       ```

**Additional Steps When Assumptions Fail**

- **Multiple Comparisons Adjustment:** When performing post-hoc tests, adjust p-values to control for Type I error.
  - **R Code Example:**
    ```R
    pairwise.t.test(your_data$Y, your_data$Group, p.adjust.method = "bonferroni")

    # Using Tukey's HSD with Robust Standard Errors
    library(multcomp)
    model <- lm(Y ~ Group, data=your_data)
    TukeyResult <- glht(model, mcp(Group = "Tukey"), vcov = vcovHC(model))
    summary(TukeyResult)
    plot(TukeyResult)
    ```

- **Using Generalized Least Squares (GLS)** to handle both heteroskedasticity and autocorrelation in ANOVA models.
  - **R Code Example:**
    ```R
    library(nlme)
    # Homoscedastic Model
    model_gls_homo <- gls(Y ~ Factor, data=your_data)

    # Heteroscedastic Model
    model_gls_hetro <- gls(Y ~ Factor, weights=varIdent(form=~1|Factor), data=your_data)
    summary(model_gls_hetro)

    # Compare Models
    anova(model_gls_homo, model_gls_hetro)
    ```

---

This compressed guide outlines the key assumptions for both Regression and ANOVA analyses, the corresponding tests to validate these assumptions, and the R code required to perform these tests. It also provides remedial measures and associated R code in cases where assumptions are violated.


---
# References for SCIE4402 W6
